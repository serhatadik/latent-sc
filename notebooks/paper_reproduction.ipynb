{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Reproduction Notebook\n",
    "\n",
    "**Georeferenced Spectrum Occupancy Analysis Using Spatially Very Sparse Monitoring Data**\n",
    "\n",
    "Serhat Tadik, Neal Patwari, Kirk Webb, Xuan Lin, Gregory D. Durgin\n",
    "\n",
    "*IEEE Journal of Radio Frequency Identification*, 2024\n",
    "\n",
    "---\n",
    "\n",
    "This notebook provides an interactive walkthrough for reproducing all results from the paper using the modular codebase.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. **Setup & Configuration**\n",
    "2. **Data Loading & Processing** (Figure 2, Table I)\n",
    "3. **Signal Estimation via Localization** (Figure 3, Table II)\n",
    "4. **Spatial Occupancy Mapping** (Figure 4)\n",
    "5. **Temporal Analysis** (Figure 5, Table III)\n",
    "6. **Variance Regression** (Figure 6)\n",
    "7. **Confidence Mapping** (Figure 7)\n",
    "8. **Full Pipeline Execution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Import our modular functions\n",
    "from src.data_processing import load_monitoring_data, compute_occupancy_metrics, compute_temporal_metrics\n",
    "from src.localization import estimate_transmit_power_map, build_covariance_matrix, compute_transmitter_pmf, estimate_received_power_map\n",
    "from src.interpolation import idw_interpolation_map, compute_confidence_map\n",
    "from src.analysis import analyze_metric_correlations, train_variance_regression\n",
    "from src.visualization.spatial_plots import *\n",
    "from src.visualization.temporal_plots import *\n",
    "from src.visualization.analysis_plots import *\n",
    "from src.utils import load_slc_map, dB_to_lin, lin_to_dB\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('../config/parameters.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "with open('../config/monitoring_locations.yaml', 'r') as f:\n",
    "    locations_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Frequency bands: {list(config['frequency_bands'].keys())}\")\n",
    "print(f\"  Monitoring stations: {len(locations_config['data_points'])}\")\n",
    "print(f\"  Map downsample factor: {config['spatial']['downsample_factor']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SLC map\n",
    "print(\"Loading SLC map...\")\n",
    "map_data = load_slc_map(\n",
    "    map_folder_dir=\"../\",\n",
    "    downsample_factor=config['spatial']['downsample_factor']\n",
    ")\n",
    "\n",
    "print(f\"✓ Map loaded:\")\n",
    "print(f\"  Shape: {map_data['shape']}\")\n",
    "print(f\"  DEM min/max: {map_data['dem'].min():.1f} / {map_data['dem'].max():.1f} m\")\n",
    "print(f\"  Buildings max height: {map_data['buildings'].max():.1f} m\")\n",
    "\n",
    "# Visualize map\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "im1 = axes[0].imshow(map_data['dem'], cmap='terrain')\n",
    "axes[0].set_title('Digital Elevation Model (DEM)')\n",
    "plt.colorbar(im1, ax=axes[0], label='Elevation (m)')\n",
    "\n",
    "im2 = axes[1].imshow(map_data['buildings'], cmap='gray')\n",
    "axes[1].set_title('Building Heights')\n",
    "plt.colorbar(im2, ax=axes[1], label='Height (m)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Processing (Figure 2, Table I)\n",
    "\n",
    "Load spectrum monitoring data and compute occupancy metrics for all bands and monitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Select band and monitor for demonstration\nBAND_NAME = \"3610-3650\"  # Options: \"2160.5-2169.5\", \"3470-3510\", \"3610-3650\"\nMONITOR_NAME = 'Bookstore'  # First monitoring station\n\nband_config = config['frequency_bands'][BAND_NAME]\n\nprint(f\"Processing {band_config['description']}\")\nprint(f\"  Frequency range: {band_config['start']}-{band_config['end']} MHz\")\nprint(f\"  Threshold: {band_config['threshold_start']} dB\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw monitoring data\n",
    "df = load_monitoring_data(\n",
    "    monitor_name=MONITOR_NAME,\n",
    "    band_start=band_config['start'],\n",
    "    band_end=band_config['end'],\n",
    "    base_path='../data/raw/rfbaseline/',\n",
    "    cutoff_date=config['data']['cutoff_date']\n",
    ")\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"✓ Data loaded: {len(df)} measurements\")\n",
    "    print(f\"  Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"⚠ No data available for this monitor/band combination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute occupancy metrics\n",
    "if df is not None:\n",
    "    metrics = compute_occupancy_metrics(\n",
    "        df=df,\n",
    "        band_start=band_config['start'],\n",
    "        band_end=band_config['end'],\n",
    "        threshold_start=band_config['threshold_start'],\n",
    "        threshold_end=band_config['threshold_end']\n",
    "    )\n",
    "\n",
    "    print(f\"Occupancy Metrics for {MONITOR_NAME}:\")\n",
    "    print(f\"  Duty Cycle: {metrics['duty_cycle']:.2f}%\")\n",
    "    print(f\"  Avg Power (occupied): {metrics['avg_power_occupied']:.2f} dB\")\n",
    "    print(f\"  Signal Variation: {metrics['signal_variation']:.2f} dB²\")\n",
    "\n",
    "    # Generate Figure 2: Power histogram\n",
    "    fig, ax = plot_power_histogram(\n",
    "        power_data=df['power'],\n",
    "        threshold=band_config['threshold_start'],\n",
    "        band_start=band_config['start'],\n",
    "        band_end=band_config['end'],\n",
    "        monitor_name=MONITOR_NAME\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process All Monitors\n",
    "\n",
    "Compute occupancy metrics for all monitoring stations to build the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all monitors for the selected band\n",
    "all_metrics = {}\n",
    "\n",
    "for location in locations_config['data_points']:\n",
    "    monitor_name = location['name']\n",
    "    print(f\"\\nProcessing {monitor_name}...\")\n",
    "\n",
    "    df = load_monitoring_data(\n",
    "        monitor_name=monitor_name,\n",
    "        band_start=band_config['start'],\n",
    "        band_end=band_config['end'],\n",
    "        base_path='../data/raw/rfbaseline/',\n",
    "        cutoff_date=config['data']['cutoff_date']\n",
    "    )\n",
    "\n",
    "    if df is not None and len(df) > 0:\n",
    "        metrics = compute_occupancy_metrics(\n",
    "            df=df,\n",
    "            band_start=band_config['start'],\n",
    "            band_end=band_config['end'],\n",
    "            threshold_start=band_config['threshold_start'],\n",
    "            threshold_end=band_config['threshold_end']\n",
    "        )\n",
    "        all_metrics[monitor_name] = metrics\n",
    "        print(f\"  ✓ DC={metrics['duty_cycle']:.1f}%, Pow={metrics['avg_power_occupied']:.1f} dB, Var={metrics['signal_variation']:.1f} dB²\")\n",
    "    else:\n",
    "        print(f\"  ⚠ No data\")\n",
    "\n",
    "print(f\"\\n✓ Processed {len(all_metrics)} monitoring stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary_data = []\n",
    "for monitor_name, metrics in all_metrics.items():\n",
    "    summary_data.append({\n",
    "        'Monitor': monitor_name,\n",
    "        'Duty Cycle (%)': f\"{metrics['duty_cycle']:.2f}\",\n",
    "        'Avg Power (dB)': f\"{metrics['avg_power_occupied']:.2f}\",\n",
    "        'Variation (dB²)': f\"{metrics['signal_variation']:.2f}\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nOccupancy Metrics Summary:\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Signal Estimation via Localization (Figure 3, Table II)\n",
    "\n",
    "Apply the likelihood-based localization algorithm to estimate signal strength across the geographic region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for localization\n",
    "data_points = np.array([loc['coordinates'] for loc in locations_config['data_points']])\n",
    "observed_powers = np.array([all_metrics[loc['name']]['avg_power_occupied'] \n",
    "                           for loc in locations_config['data_points'] \n",
    "                           if loc['name'] in all_metrics])\n",
    "\n",
    "print(f\"Localization input:\")\n",
    "print(f\"  {len(data_points)} monitoring stations\")\n",
    "print(f\"  Observed powers: {observed_powers}\")\n",
    "print(f\"  Power range: [{observed_powers.min():.1f}, {observed_powers.max():.1f}] dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Estimate transmit power map (Equation 3)\n",
    "print(\"Estimating transmit power at all locations...\")\n",
    "\n",
    "transmit_power_map = estimate_transmit_power_map(\n",
    "    map_shape=map_data['shape'],\n",
    "    sensor_locations=data_points,\n",
    "    observed_powers=observed_powers,\n",
    "    scale=config['localization']['proxel_size'],\n",
    "    np_exponent=config['localization']['path_loss_exponent'],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"✓ Transmit power map: shape {transmit_power_map.shape}\")\n",
    "print(f\"  Range: [{transmit_power_map.min():.1f}, {transmit_power_map.max():.1f}] dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transmit power map (Figure 3a)\n",
    "fig, ax = plot_transmit_power_map(\n",
    "    transmit_power_map=transmit_power_map,\n",
    "    data_points=data_points,\n",
    "    observed_powers=observed_powers,\n",
    "    UTM_lat=map_data['UTM_lat'],\n",
    "    UTM_long=map_data['UTM_long'],\n",
    "    band_name=BAND_NAME\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build covariance matrix (Equation 5)\n",
    "print(\"Building covariance matrix...\")\n",
    "\n",
    "cov_matrix = build_covariance_matrix(\n",
    "    sensor_locations=data_points,\n",
    "    sigma=config['localization']['std_deviation'],\n",
    "    delta_c=config['localization']['correlation_coeff'],\n",
    "    scale=config['localization']['proxel_size']\n",
    ")\n",
    "\n",
    "print(f\"✓ Covariance matrix: shape {cov_matrix.shape}\")\n",
    "print(f\"  Condition number: {np.linalg.cond(cov_matrix):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute transmitter PMF (Equation 4)\n",
    "print(\"Computing transmitter probability mass function...\")\n",
    "\n",
    "pmf = compute_transmitter_pmf(\n",
    "    transmit_power_map=transmit_power_map,\n",
    "    sensor_locations=data_points,\n",
    "    observed_powers=observed_powers,\n",
    "    cov_matrix=cov_matrix,\n",
    "    scale=config['localization']['proxel_size'],\n",
    "    np_exponent=config['localization']['path_loss_exponent']\n",
    ")\n",
    "\n",
    "print(f\"✓ PMF computed: shape {pmf.shape}\")\n",
    "print(f\"  PMF sum: {np.sum(pmf):.6f} (should be ≈ 1.0)\")\n",
    "\n",
    "most_likely_idx = np.unravel_index(pmf.argmax(), pmf.shape)\n",
    "print(f\"  Most likely transmitter location: {most_likely_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PMF (Figure 3b)\n",
    "fig, ax = plot_pmf_map(\n",
    "    pmf=pmf,\n",
    "    data_points=data_points,\n",
    "    observed_powers=observed_powers,\n",
    "    UTM_lat=map_data['UTM_lat'],\n",
    "    UTM_long=map_data['UTM_long'],\n",
    "    band_name=BAND_NAME\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Estimate received power map (Equation 6)\n",
    "print(\"Estimating received power at all locations...\")\n",
    "\n",
    "# Create target grid (all pixels)\n",
    "rows, cols = map_data['shape']\n",
    "target_grid = []\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        target_grid.append([i, j])\n",
    "target_grid = np.array(target_grid)\n",
    "\n",
    "signal_estimates = estimate_received_power_map(\n",
    "    transmit_power_map=transmit_power_map,\n",
    "    pmf=pmf,\n",
    "    sensor_locations=data_points,\n",
    "    target_grid=target_grid,\n",
    "    scale=config['localization']['proxel_size'],\n",
    "    np_exponent=config['localization']['path_loss_exponent']\n",
    ")\n",
    "\n",
    "# Reshape to 2D map\n",
    "signal_estimates_2d = signal_estimates.reshape(map_data['shape'])\n",
    "print(f\"✓ Signal estimates: shape {signal_estimates_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize signal estimates (Figure 3c)\n",
    "fig, ax = plot_signal_estimates_map(\n",
    "    signal_estimates=signal_estimates_2d,\n",
    "    data_points=data_points,\n",
    "    observed_powers=observed_powers,\n",
    "    UTM_lat=map_data['UTM_lat'],\n",
    "    UTM_long=map_data['UTM_long'],\n",
    "    band_name=BAND_NAME\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics (Table II)\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "\n",
    "mse_scores = []\n",
    "for i, loc in enumerate(locations_config['data_points']):\n",
    "    if loc['name'] not in all_metrics:\n",
    "        continue\n",
    "\n",
    "    actual = all_metrics[loc['name']]['avg_power_occupied']\n",
    "    predicted = lin_to_dB(signal_estimates_2d[data_points[i, 1], data_points[i, 0]])\n",
    "    error = (actual - predicted) ** 2\n",
    "    mse_scores.append(error)\n",
    "    print(f\"  {loc['name']:15s}: Actual={actual:6.2f}, Predicted={predicted:6.2f}, MSE={error:6.2f}\")\n",
    "\n",
    "mse_scores = np.array(mse_scores)\n",
    "mean_mse = np.mean(mse_scores)\n",
    "variance_baseline = np.var(observed_powers)\n",
    "\n",
    "print(f\"\\n  Mean MSE: {mean_mse:.2f} dB²\")\n",
    "print(f\"  Baseline variance: {variance_baseline:.2f} dB²\")\n",
    "print(f\"  Variance reduction: {(1 - mean_mse/variance_baseline)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial Occupancy Mapping (Figure 4)\n",
    "\n",
    "Create combined visualization showing both power (color) and duty cycle (square size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate duty cycle to full map using IDW\n",
    "duty_cycles = np.array([all_metrics[loc['name']]['duty_cycle'] \n",
    "                        for loc in locations_config['data_points'] \n",
    "                        if loc['name'] in all_metrics])\n",
    "\n",
    "duty_cycle_map = idw_interpolation_map(\n",
    "    x_known=data_points[:, 0],\n",
    "    y_known=data_points[:, 1],\n",
    "    z_known=duty_cycles,\n",
    "    map_shape=map_data['shape'],\n",
    "    power=2\n",
    ")\n",
    "\n",
    "print(f\"✓ Duty cycle map interpolated: shape {duty_cycle_map.shape}\")\n",
    "print(f\"  Range: [{duty_cycle_map.min():.1f}, {duty_cycle_map.max():.1f}]%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined power/duty cycle visualization (Figure 4)\n",
    "power_map = lin_to_dB(signal_estimates_2d)\n",
    "\n",
    "fig, ax = plot_power_duty_cycle_combined(\n",
    "    power_map=power_map,\n",
    "    duty_cycle_map=duty_cycle_map,\n",
    "    data_points=data_points,\n",
    "    buildings_map=map_data['buildings'],\n",
    "    UTM_lat=map_data['UTM_lat'],\n",
    "    UTM_long=map_data['UTM_long'],\n",
    "    band_name=BAND_NAME,\n",
    "    block_size=5\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Temporal Analysis (Figure 5, Table III)\n",
    "\n",
    "Analyze spectrum occupancy patterns across time-of-day and seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute temporal metrics for one monitor\n",
    "df = load_monitoring_data(\n",
    "    monitor_name=MONITOR_NAME,\n",
    "    band_start=band_config['start'],\n",
    "    band_end=band_config['end'],\n",
    "    base_path='../data/raw/rfbaseline/',\n",
    "    cutoff_date=config['data']['cutoff_date']\n",
    ")\n",
    "\n",
    "if df is not None:\n",
    "    temporal_metrics = compute_temporal_metrics(\n",
    "        df=df,\n",
    "        band_start=band_config['start'],\n",
    "        band_end=band_config['end'],\n",
    "        threshold_start=band_config['threshold_start'],\n",
    "        threshold_end=band_config['threshold_end']\n",
    "    )\n",
    "\n",
    "    print(\"Time-of-Day Metrics:\")\n",
    "    for period, metrics in temporal_metrics['time_of_day'].items():\n",
    "        print(f\"  {period:12s}: DC={metrics['duty_cycle']:6.2f}%, Pow={metrics['avg_power_occupied']:7.2f} dB, Var={metrics['signal_variation']:6.2f} dB²\")\n",
    "\n",
    "    print(\"\\nSeasonal Metrics:\")\n",
    "    for season, metrics in temporal_metrics['season'].items():\n",
    "        print(f\"  {season:12s}: DC={metrics['duty_cycle']:6.2f}%, Pow={metrics['avg_power_occupied']:7.2f} dB, Var={metrics['signal_variation']:6.2f} dB²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temporal analysis (Figure 5)\n",
    "if df is not None:\n",
    "    fig, axes = plot_all_temporal_metrics(\n",
    "        temporal_metrics=temporal_metrics,\n",
    "        monitor_name=MONITOR_NAME,\n",
    "        band_name=BAND_NAME\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations (Table III)\n",
    "correlations = analyze_metric_correlations(\n",
    "    rssi=observed_powers,\n",
    "    variance=np.array([all_metrics[loc['name']]['signal_variation'] \n",
    "                       for loc in locations_config['data_points'] \n",
    "                       if loc['name'] in all_metrics]),\n",
    "    duty_cycle=duty_cycles\n",
    ")\n",
    "\n",
    "print(\"\\nCorrelation Coefficients (Table III):\")\n",
    "print(f\"  Variance vs RSSI:       {correlations['variance_mean_power']:7.3f}\")\n",
    "print(f\"  Variance vs Duty Cycle: {correlations['variance_duty_cycle']:7.3f}\")\n",
    "print(f\"  Duty Cycle vs RSSI:     {correlations['duty_cycle_mean_power']:7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Variance Regression (Figure 6)\n",
    "\n",
    "Train polynomial regression model to predict signal variation from RSSI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "variance_values = np.array([all_metrics[loc['name']]['signal_variation'] \n",
    "                            for loc in locations_config['data_points'] \n",
    "                            if loc['name'] in all_metrics])\n",
    "\n",
    "print(f\"Training variance regression model...\")\n",
    "print(f\"  Training on {len(observed_powers)} monitoring stations\")\n",
    "print(f\"  RSSI range: [{observed_powers.min():.2f}, {observed_powers.max():.2f}] dB\")\n",
    "print(f\"  Variance range: [{variance_values.min():.2f}, {variance_values.max():.2f}] dB²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = train_variance_regression(\n",
    "    rssi_data=observed_powers,\n",
    "    variance_data=variance_values,\n",
    "    degree=3,\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "# Calculate R² score\n",
    "from sklearn.metrics import r2_score\n",
    "variance_pred = model.predict(observed_powers.reshape(-1, 1))\n",
    "r2 = r2_score(variance_values, variance_pred)\n",
    "\n",
    "print(f\"✓ Model trained: R² = {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regression (Figure 6)\n",
    "fig, ax = plot_variance_regression(\n",
    "    rssi_data=observed_powers,\n",
    "    variance_data=variance_values,\n",
    "    model=model,\n",
    "    band_name=BAND_NAME\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confidence Mapping (Figure 7)\n",
    "\n",
    "Create confidence level map showing reliability of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confidence map\n",
    "confidence_map = compute_confidence_map(\n",
    "    data_points=data_points,\n",
    "    map_shape=map_data['shape'],\n",
    "    alpha=0.01  # From paper\n",
    ")\n",
    "\n",
    "print(f\"✓ Confidence map computed: shape {confidence_map.shape}\")\n",
    "print(f\"  Range: [{confidence_map.min():.3f}, {confidence_map.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize variation and confidence (Figure 7)\n",
    "fig, axes = plot_variation_confidence_combined(\n",
    "    variation_map=duty_cycle_map,  # Using duty_cycle_map as proxy for variation map\n",
    "    confidence_map=confidence_map,\n",
    "    data_points=data_points,\n",
    "    UTM_lat=map_data['UTM_lat'],\n",
    "    UTM_long=map_data['UTM_long'],\n",
    "    band_name=BAND_NAME\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Full Pipeline Execution\n",
    "\n",
    "Run the complete pipeline using the command-line scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Option 1: Run individual pipeline steps\nprint(\"To run individual pipeline steps:\")\nprint(\"  1. python scripts/01_process_occupancy.py\")\nprint(\"  2. python scripts/02_estimate_signals.py\")\nprint(\"  3. python scripts/03_temporal_analysis.py\")\nprint(\"  4. python scripts/04_generate_figures.py\")\n\nprint(\"\\nOption 2: Run full pipeline at once:\")\nprint(\"  python scripts/run_full_pipeline.py\")\n\nprint(\"\\nFor specific bands:\")\nprint('  python scripts/run_full_pipeline.py --band \"3610-3650\"')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete workflow for reproducing the paper results:\n",
    "\n",
    "1. ✓ Data loading and occupancy metric computation\n",
    "2. ✓ Likelihood-based signal strength estimation\n",
    "3. ✓ Spatial occupancy mapping\n",
    "4. ✓ Temporal analysis (time-of-day and seasonal)\n",
    "5. ✓ Variance prediction via regression\n",
    "6. ✓ Confidence level mapping\n",
    "\n",
    "All figures from the paper can be reproduced using the modular codebase.\n",
    "\n",
    "For automated batch processing, use the pipeline scripts in `scripts/`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}