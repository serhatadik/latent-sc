{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Reconstruction Localization Analysis\n",
    "\n",
    "This notebook demonstrates the **joint sparse superposition reconstruction** approach for transmitter localization:\n",
    "1. Load processed power measurements from monitoring locations\n",
    "2. Convert data from dB to linear scale\n",
    "3. Run sparse reconstruction algorithm\n",
    "4. Visualize sparse transmit power field\n",
    "5. Compare with likelihood-based approach\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Sparse Reconstruction Formulation:**\n",
    "\n",
    "$$\\hat{\\mathbf{t}} = \\arg\\min_{\\mathbf{t}\\ge 0} \\|\\mathbf{W}(\\log_{10}(\\mathbf{A}_{\\text{model}}\\mathbf{t}) - \\log_{10}(\\mathbf{p}))\\|_{2}^{2} + \\lambda \\|\\mathbf{t}\\|_{1}$$\n",
    "\n",
    "**Key Features:**\n",
    "- Single-stage joint optimization (vs. two-stage likelihood)\n",
    "- Explicit sparsity constraint (few active transmitters)\n",
    "- Convex optimization (global optimum guaranteed)\n",
    "- Fast computation (~10-30 seconds vs. 5-10 minutes)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Configuration\n",
    "\n",
    "Import modules and configure the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Import utility functions\n",
    "from src.utils import (\n",
    "    load_slc_map, \n",
    "    load_monitoring_locations, \n",
    "    get_sensor_locations_array,\n",
    "    load_transmitter_locations,\n",
    "    lin_to_dB\n",
    ")\n",
    "\n",
    "# Import SPARSE RECONSTRUCTION modules\n",
    "from src.sparse_reconstruction import (\n",
    "    joint_sparse_reconstruction,\n",
    "    compute_signal_strength_at_points,\n",
    "    dbm_to_linear,\n",
    "    linear_to_dbm\n",
    ")\n",
    "\n",
    "# Import visualization\n",
    "from src.visualization.spatial_plots import (\n",
    "    plot_transmit_power_map,\n",
    "    plot_signal_estimates_map\n",
    ")\n",
    "\n",
    "print(\"✓ Modules imported successfully\")\n",
    "print(\"✓ Using SPARSE RECONSTRUCTION algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure which transmitter(s) to analyze\n",
    "TRANSMITTERS = ['moran']  # Change as needed\n",
    "TRANSMITTER_COMMA = \",\".join(TRANSMITTERS)\n",
    "TRANSMITTER_UNDERSCORE = \"_\".join(TRANSMITTERS)\n",
    "\n",
    "print(f\"Analyzing transmitter(s): {TRANSMITTER_COMMA}\")\n",
    "\n",
    "# Set file paths\n",
    "CUSTOM_YAML = f'../config/monitoring_locations_{TRANSMITTER_UNDERSCORE}.yaml'\n",
    "DATA_DIR = Path(f'../data/processed/{TRANSMITTER_UNDERSCORE}/')\n",
    "\n",
    "print(f\"Configuration file: {CUSTOM_YAML}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Map and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('../config/parameters.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Proxel size: {config['spatial']['proxel_size']} m/pixel\")\n",
    "print(f\"  Path loss exponent: {config['localization']['path_loss_exponent']}\")\n",
    "print(f\"  Shadowing σ: {config['localization']['std_deviation']} dB\")\n",
    "print(f\"  Correlation distance δ_c: {config['localization']['correlation_coeff']} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SLC map\n",
    "print(\"Loading SLC map...\")\n",
    "map_data = load_slc_map(\n",
    "    map_folder_dir=\"../\",\n",
    "    downsample_factor=config['spatial']['downsample_factor']\n",
    ")\n",
    "\n",
    "print(f\"✓ Map loaded: shape {map_data['shape']}\")\n",
    "print(f\"  UTM Easting range: [{map_data['UTM_long'].min():.1f}, {map_data['UTM_long'].max():.1f}] m\")\n",
    "print(f\"  UTM Northing range: [{map_data['UTM_lat'].min():.1f}, {map_data['UTM_lat'].max():.1f}] m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transmitter locations for visualization\n",
    "print(\"Loading transmitter locations...\")\n",
    "all_tx_locations = load_transmitter_locations(\n",
    "    config_path='../config/transmitter_locations.yaml',\n",
    "    map_data=map_data\n",
    ")\n",
    "\n",
    "# Filter to only show transmitters being analyzed\n",
    "tx_locations = {name: all_tx_locations[name] for name in TRANSMITTERS if name in all_tx_locations}\n",
    "\n",
    "print(f\"✓ Loaded {len(tx_locations)} transmitter location(s) for display\")\n",
    "print(f\"\\nTransmitter Locations:\")\n",
    "for tx_name, tx_data in tx_locations.items():\n",
    "    print(f\"  {tx_name:12s}: ({tx_data['latitude']:.6f}, {tx_data['longitude']:.6f}) → {tx_data['coordinates']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Monitoring Locations and Power Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load monitoring locations\n",
    "print(f\"Loading monitoring locations from {CUSTOM_YAML}...\")\n",
    "locations_config = load_monitoring_locations(\n",
    "    config_path=CUSTOM_YAML,\n",
    "    map_data=map_data\n",
    ")\n",
    "\n",
    "print(f\"✓ Loaded {len(locations_config['data_points'])} monitoring locations\")\n",
    "print(f\"  UTM Zone: {locations_config['utm_zone']}{'N' if locations_config['northern_hemisphere'] else 'S'}\")\n",
    "\n",
    "# Display locations\n",
    "print(\"\\nMonitoring Locations:\")\n",
    "for loc in locations_config['data_points']:\n",
    "    print(f\"  {loc['name']:12s}: ({loc['latitude']:.5f}, {loc['longitude']:.5f}) → {loc['coordinates']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed power measurements (in dB)\n",
    "print(f\"\\nLoading power measurements from {DATA_DIR}...\")\n",
    "\n",
    "observed_powers_dB = np.load(DATA_DIR / f\"{TRANSMITTER_UNDERSCORE}_avg_powers.npy\")\n",
    "power_stds = np.load(DATA_DIR / f\"{TRANSMITTER_UNDERSCORE}_std_powers.npy\")\n",
    "sample_counts = np.load(DATA_DIR / f\"{TRANSMITTER_UNDERSCORE}_sample_counts.npy\")\n",
    "\n",
    "print(f\"✓ Loaded power measurements:\")\n",
    "print(f\"  Number of sensors: {len(observed_powers_dB)}\")\n",
    "print(f\"  Power range: [{observed_powers_dB.min():.2f}, {observed_powers_dB.max():.2f}] dB\")\n",
    "print(f\"  Total samples: {sample_counts.sum()}\")\n",
    "print(f\"  Observed powers (dB): {observed_powers_dB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary table\n",
    "summary_df = pd.read_csv(DATA_DIR / f\"{TRANSMITTER_UNDERSCORE}_summary.csv\")\n",
    "print(\"\\nPower Measurement Summary:\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Convert Data for Sparse Reconstruction\n",
    "\n",
    "The sparse reconstruction algorithm works in **linear power scale** (mW), not dB.\n",
    "\n",
    "**Conversion:** $P[\\text{mW}] = 10^{P[\\text{dBm}]/10}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert observed powers from dBm to linear scale (mW)\n",
    "observed_powers_linear = dbm_to_linear(observed_powers_dB)\n",
    "\n",
    "print(\"Unit Conversion:\")\n",
    "print(f\"  Input (dBm):  {observed_powers_dB}\")\n",
    "print(f\"  Output (mW):  {observed_powers_linear}\")\n",
    "print(f\"\\n  Linear scale range: [{observed_powers_linear.min():.2e}, {observed_powers_linear.max():.2e}] mW\")\n",
    "\n",
    "# Note: These are very small numbers (e.g., 1e-8 mW = 1e-11 W = 10 pW)\n",
    "# This is normal for RF propagation at ~100m distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sensor locations in pixel coordinates\n",
    "sensor_locations = get_sensor_locations_array(locations_config)\n",
    "\n",
    "print(f\"Sensor locations (pixel coordinates):\")\n",
    "print(f\"  Shape: {sensor_locations.shape}\")\n",
    "print(f\"  Array: {sensor_locations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run Sparse Reconstruction Algorithm\n",
    "\n",
    "**Optimization Problem:**\n",
    "\n",
    "$$\\hat{\\mathbf{t}} = \\arg\\min_{\\mathbf{t}\\ge 0} \\|\\mathbf{W}(\\log_{10}(\\mathbf{A}_{\\text{model}}\\mathbf{t}) - \\log_{10}(\\mathbf{p}))\\|_{2}^{2} + \\lambda \\|\\mathbf{t}\\|_{1}$$\n",
    "\n",
    "**Parameters:**\n",
    "- $\\mathbf{t}$: Transmit power field (N grid points)\n",
    "- $\\mathbf{p}$: Observed powers (M sensors)\n",
    "- $\\mathbf{A}_{\\text{model}}$: Propagation matrix (linear path gains)\n",
    "- $\\mathbf{W}$: Whitening matrix ($\\mathbf{V}^{-1/2}$)\n",
    "- $\\lambda$: Sparsity regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set regularization parameter\n",
    "# Larger λ → sparser solution (fewer transmitters)\n",
    "# Smaller λ → denser solution (more transmitters)\n",
    "# Good starting point: λ = 0.001 * norm(observed_powers)\n",
    "\n",
    "# Log-domain heuristic: scale inversely with power to balance unitless data term\n",
    "# Data term is ~O(1) (dB squared error), Reg term is λ * power (Watts)\n",
    "# So we need λ * 1e-8 ≈ 1 => λ ≈ 1e8\n",
    "mean_power = np.mean(observed_powers_linear)\n",
    "#lambda_reg = 50 / mean_power\n",
    "lambda_reg = 0\n",
    "gamma = 0\n",
    "print(f\"Regularization parameter: λ = {lambda_reg:.2e}\")\n",
    "print(f\"  (Automatically scaled: 0.1 / mean(p))\")\n",
    "print(f\"\\nNote: You can adjust λ to control sparsity:\")\n",
    "print(f\"  - Increase λ for sparser solution (fewer transmitters)\")\n",
    "print(f\"  - Decrease λ for denser solution (more transmitters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sparse reconstruction\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RUNNING SPARSE RECONSTRUCTION ALGORITHM\")\n",
    "print(\"=\"*70)\n",
    "exclusion_radius=0\n",
    "max_l2_norm = 1\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "'''tx_map_sparse_baseline, info_sparse_baseline = joint_sparse_reconstruction(\n",
    "    sensor_locations=sensor_locations,\n",
    "    observed_powers_dBm=observed_powers_dB,  # Function converts internally\n",
    "    map_shape=map_data['shape'],\n",
    "    scale=config['spatial']['proxel_size'],\n",
    "    np_exponent=config['localization']['path_loss_exponent'],\n",
    "    sigma=config['localization']['std_deviation'],\n",
    "    delta_c=config['localization']['correlation_coeff'],\n",
    "    lambda_reg=lambda_reg,\n",
    "    gamma=gamma,\n",
    "    max_l2_norm=max_l2_norm,\n",
    "    norm_exponent=0.5,\n",
    "    enable_reweighting=False,\n",
    "    sparsity_threshold=1e-11,\n",
    "    whitening_method='covariance',\n",
    "    exclusion_radius=exclusion_radius,\n",
    "    solver='l-bfgs-b',  # Use scipy L-BFGS-B for non-convex log-domain objective\n",
    "    return_linear_scale=False,  # Return in dBm for visualization\n",
    "    verbose=True,\n",
    "    model_type='tirem',\n",
    "    tirem_config_path='../config/tirem_parameters.yaml',\n",
    "    n_jobs=-1 \n",
    ")'''\n",
    "\n",
    "tx_map_sparse_reweighted, info_sparse_reweighted = joint_sparse_reconstruction(\n",
    "    sensor_locations=sensor_locations,\n",
    "    observed_powers_dBm=observed_powers_dB,  # Function converts internally\n",
    "    map_shape=map_data['shape'],\n",
    "    scale=config['spatial']['proxel_size'],\n",
    "    np_exponent=config['localization']['path_loss_exponent'],\n",
    "    sigma=config['localization']['std_deviation'],\n",
    "    delta_c=config['localization']['correlation_coeff'],\n",
    "    lambda_reg=lambda_reg,\n",
    "    gamma=gamma,\n",
    "    max_l2_norm=max_l2_norm,\n",
    "    norm_exponent=0,\n",
    "    enable_reweighting=False,\n",
    "    #max_reweight_iter=3,        # Fewer iterations\n",
    "    #reweight_epsilon=1e-6,      # Different damping\n",
    "    #convergence_tol=1e-8,       # Looser convergence\n",
    "    sparsity_threshold=1e-11,\n",
    "    whitening_method='hetero_diag',\n",
    "    sigma_noise=1e-13,\n",
    "    eta=0.5,\n",
    "    exclusion_radius=exclusion_radius,\n",
    "    solver='glrt',  # Use scipy L-BFGS-B for non-convex log-domain objective\n",
    "    return_linear_scale=False,  # Return in dBm for visualization\n",
    "    verbose=True,\n",
    "    model_type='tirem',\n",
    "    tirem_config_path='../config/tirem_parameters.yaml',\n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✓ Reconstruction completed in {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Sparse Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display reconstruction statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SPARSE RECONSTRUCTION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "'''\n",
    "print(f\"\\nSparsity Statistics:\")\n",
    "print(f\"  Grid size: {map_data['shape'][0]} × {map_data['shape'][1]} = {np.prod(map_data['shape'])} pixels\")\n",
    "print(f\"  Non-zero entries: {info_sparse_baseline['n_nonzero']}\")\n",
    "print(f\"  Sparsity: {info_sparse_baseline['sparsity']*100:.2f}% (fraction of zeros)\")\n",
    "print(f\"  Active fraction: {(1-info_sparse_baseline['sparsity'])*100:.4f}%\")\n",
    "\n",
    "print(f\"\\nPeak Location:\")\n",
    "peak_row, peak_col = info_sparse_baseline['peak_location']\n",
    "print(f\"  Pixel coordinates: (row={peak_row}, col={peak_col})\")\n",
    "print(f\"  Peak power: {info_sparse_baseline['peak_power_dBm']:.1f} dBm\")\n",
    "print(f\"  Peak power (linear): {info_sparse_baseline['peak_power_linear']:.2e} mW\")\n",
    "\n",
    "print(f\"\\nSolver Information:\")\n",
    "print(f\"  Solver used: {info_sparse_baseline['solver_info']['solver_used']}\")\n",
    "print(f\"  Success: {info_sparse_baseline['solver_info']['success']}\")\n",
    "\n",
    "print(f\"\\nComputational Efficiency:\")\n",
    "print(f\"  Total time: {elapsed_time:.2f} seconds\")\n",
    "print(f\"  (~10-50x faster than likelihood-based approach)\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top-K non-zero locations\n",
    "K = 10  # Number of top locations to display\n",
    "'''\n",
    "# Convert to linear scale for sorting\n",
    "tx_map_linear_baseline = dbm_to_linear(tx_map_sparse_baseline)\n",
    "flat_powers_baseline = tx_map_linear_baseline.ravel()\n",
    "top_k_indices_baseline = np.argsort(flat_powers_baseline)[-K:][::-1]  # Top K descending\n",
    "\n",
    "print(f\"\\nTop {K} Transmitter Locations (by power):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Rank':<6} {'Row':<8} {'Col':<8} {'Power (dBm)':<15} {'Power (mW)':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for rank, idx in enumerate(top_k_indices_baseline, 1):\n",
    "    row = idx // map_data['shape'][1]\n",
    "    col = idx % map_data['shape'][1]\n",
    "    power_linear = flat_powers_baseline[idx]\n",
    "    power_dBm = linear_to_dbm(power_linear)\n",
    "    \n",
    "    if power_linear > 1e-15:  # Only show non-negligible values\n",
    "        print(f\"{rank:<6} {row:<8} {col:<8} {power_dBm:<15.2f} {power_linear:<15.2e}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "'''\n",
    "# Convert to linear scale for sorting\n",
    "tx_map_linear_reweighted = dbm_to_linear(tx_map_sparse_reweighted)\n",
    "flat_powers_reweighted = tx_map_linear_reweighted.ravel()\n",
    "top_k_indices_reweighted = np.argsort(flat_powers_reweighted)[-K:][::-1]  # Top K descending\n",
    "\n",
    "print(f\"\\nTop {K} Transmitter Locations (by power):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Rank':<6} {'Row':<8} {'Col':<8} {'Power (dBm)':<15} {'Power (mW)':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for rank, idx in enumerate(top_k_indices_reweighted, 1):\n",
    "    row = idx // map_data['shape'][1]\n",
    "    col = idx % map_data['shape'][1]\n",
    "    power_linear = flat_powers_reweighted[idx]\n",
    "    power_dBm = linear_to_dbm(power_linear)\n",
    "    \n",
    "    if power_linear > 1e-15:  # Only show non-negligible values\n",
    "        print(f\"{rank:<6} {row:<8} {col:<8} {power_dBm:<15.2f} {power_linear:<15.2e}\")\n",
    "\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize Sparse Transmit Power Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sparse transmit power field\n",
    "tx_name_list = \" & \".join(TRANSMITTERS)\n",
    "'''\n",
    "fig, ax = plot_transmit_power_map(\n",
    "    transmit_power_map=tx_map_sparse_baseline,\n",
    "    data_points=sensor_locations,\n",
    "    observed_powers=observed_powers_dB,\n",
    "    UTM_lat=map_data['UTM_lat'],\n",
    "    UTM_long=map_data['UTM_long'],\n",
    "    band_name=f\"{tx_name_list} Transmitter (Sparse Reconstruction)\",\n",
    "    transmitter_locations=tx_locations\n",
    ")\n",
    "\n",
    "# Add sparsity annotation\n",
    "ax.text(\n",
    "    0.02, 0.98, \n",
    "    f\"Sparsity: {info_sparse_baseline['sparsity']*100:.1f}%\\n\"\n",
    "    f\"Non-zero: {info_sparse_baseline['n_nonzero']} / {np.prod(map_data['shape'])}\\n\"\n",
    "    f\"λ = {lambda_reg:.2e}\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=10,\n",
    "    verticalalignment='top',\n",
    "    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "fig, ax = plot_transmit_power_map(\n",
    "    transmit_power_map=tx_map_sparse_reweighted,\n",
    "    data_points=sensor_locations,\n",
    "    observed_powers=observed_powers_dB,\n",
    "    UTM_lat=map_data['UTM_lat'],\n",
    "    UTM_long=map_data['UTM_long'],\n",
    "    band_name=f\"{tx_name_list} Transmitter (1 Iteration)\",\n",
    "    transmitter_locations=tx_locations\n",
    ")\n",
    "\n",
    "# Add sparsity annotation\n",
    "ax.text(\n",
    "    0.02, 0.98, \n",
    "    f\"Sparsity: {info_sparse_reweighted['sparsity']*100:.1f}%\\n\"\n",
    "    f\"Non-zero: {info_sparse_reweighted['n_nonzero']} / {np.prod(map_data['shape'])}\\n\"\n",
    "    f\"λ = {lambda_reg:.2e}\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=10,\n",
    "    verticalalignment='top',\n",
    "    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Compare Predictions with Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Compute predicted powers at sensor locations using sparse transmit field\n",
    "print(\"Computing signal strength at sensor locations...\")\n",
    "\n",
    "# Need to convert tx_map back to linear for physics-based propagation\n",
    "tx_map_linear = dbm_to_linear(tx_map_sparse)\n",
    "\n",
    "predicted_powers_linear = compute_signal_strength_at_points(\n",
    "    transmit_power_map_linear=tx_map_linear,\n",
    "    target_locations=sensor_locations,\n",
    "    scale=config['spatial']['proxel_size'],\n",
    "    np_exponent=config['localization']['path_loss_exponent'],\n",
    "    return_linear_scale=False,  # Return in dBm\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "predicted_powers_dB = predicted_powers_linear\n",
    "\n",
    "print(f\"\\n✓ Predictions computed\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Evaluation metrics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Per-sensor comparison\n",
    "print(f\"\\nPer-Sensor Comparison:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Location':<15} {'Observed (dBm)':<18} {'Predicted (dBm)':<18} {'Error (dB)':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "errors = []\n",
    "for i, loc in enumerate(locations_config['data_points']):\n",
    "    obs = observed_powers_dB[i]\n",
    "    pred = predicted_powers_dB[i]\n",
    "    error = obs - pred\n",
    "    errors.append(error)\n",
    "    print(f\"{loc['name']:<15} {obs:<18.2f} {pred:<18.2f} {error:<12.2f}\")\n",
    "\n",
    "errors = np.array(errors)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Summary statistics\n",
    "mse = np.mean(errors**2)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = np.mean(np.abs(errors))\n",
    "max_error = np.max(np.abs(errors))\n",
    "\n",
    "print(f\"\\nSummary Statistics:\")\n",
    "print(f\"  Mean Squared Error (MSE):  {mse:.2f} dB²\")\n",
    "print(f\"  Root Mean Squared Error:   {rmse:.2f} dB\")\n",
    "print(f\"  Mean Absolute Error (MAE): {mae:.2f} dB\")\n",
    "print(f\"  Max Absolute Error:        {max_error:.2f} dB\")\n",
    "\n",
    "# Compare with baseline (mean predictor)\n",
    "variance_baseline = np.var(observed_powers_dB)\n",
    "variance_reduction = (1 - mse / variance_baseline) * 100\n",
    "\n",
    "print(f\"\\n  Baseline variance (mean predictor): {variance_baseline:.2f} dB²\")\n",
    "print(f\"  Variance reduction: {variance_reduction:.1f}%\")\n",
    "\n",
    "if variance_reduction > 0:\n",
    "    print(f\"  ✓ Model outperforms baseline predictor\")\n",
    "else:\n",
    "    print(f\"  ✗ Model underperforms baseline (consider adjusting λ)\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Scatter plot: Observed vs Predicted\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ax.scatter(observed_powers_dB, predicted_powers_dB, s=100, alpha=0.7, edgecolors='k')\n",
    "\n",
    "# Add diagonal line (perfect prediction)\n",
    "min_val = min(observed_powers_dB.min(), predicted_powers_dB.min())\n",
    "max_val = max(observed_powers_dB.max(), predicted_powers_dB.max())\n",
    "ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "\n",
    "ax.set_xlabel('Observed Power (dBm)', fontsize=12)\n",
    "ax.set_ylabel('Predicted Power (dBm)', fontsize=12)\n",
    "ax.set_title('Sparse Reconstruction: Observed vs Predicted Power', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics text box\n",
    "stats_text = f\"RMSE = {rmse:.2f} dB\\nMAE = {mae:.2f} dB\\nSparsity = {info_sparse['sparsity']*100:.1f}%\"\n",
    "ax.text(\n",
    "    0.05, 0.95, stats_text,\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=10,\n",
    "    verticalalignment='top',\n",
    "    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Sensitivity Analysis - Effect of λ\n",
    "\n",
    "Explore how the regularization parameter $\\lambda$ affects sparsity and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Test different λ values\n",
    "lambda_values = [1e-4, 1e-3, 1e-2, 1e-1, 1.0]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Testing different λ values...\")\n",
    "print(\"(This may take 1-2 minutes)\\n\")\n",
    "\n",
    "for lam in lambda_values:\n",
    "    print(f\"λ = {lam:.0e}...\", end=' ')\n",
    "    \n",
    "    # Run reconstruction\n",
    "    tx_map_test, info_test = joint_sparse_reconstruction(\n",
    "        sensor_locations=sensor_locations,\n",
    "        observed_powers_dBm=observed_powers_dB,\n",
    "        map_shape=map_data['shape'],\n",
    "        scale=config['spatial']['proxel_size'],\n",
    "        np_exponent=config['localization']['path_loss_exponent'],\n",
    "        sigma=config['localization']['std_deviation'],\n",
    "        delta_c=config['localization']['correlation_coeff'],\n",
    "        lambda_reg=lam,\n",
    "        solver='auto',\n",
    "        return_linear_scale=False,\n",
    "        verbose=False  # Suppress detailed output\n",
    "    )\n",
    "    \n",
    "    # Compute predictions\n",
    "    tx_map_test_linear = dbm_to_linear(tx_map_test)\n",
    "    pred_test = compute_signal_strength_at_points(\n",
    "        transmit_power_map_linear=tx_map_test_linear,\n",
    "        target_locations=sensor_locations,\n",
    "        scale=config['spatial']['proxel_size'],\n",
    "        np_exponent=config['localization']['path_loss_exponent'],\n",
    "        return_linear_scale=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Compute error\n",
    "    rmse_test = np.sqrt(np.mean((observed_powers_dB - pred_test)**2))\n",
    "    \n",
    "    results.append({\n",
    "        'lambda': lam,\n",
    "        'sparsity': info_test['sparsity'],\n",
    "        'n_nonzero': info_test['n_nonzero'],\n",
    "        'rmse': rmse_test\n",
    "    })\n",
    "    \n",
    "    print(f\"Sparsity={info_test['sparsity']*100:.1f}%, RMSE={rmse_test:.2f} dB\")\n",
    "\n",
    "print(\"\\n✓ Sensitivity analysis complete\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Plot λ sensitivity\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Sparsity vs λ\n",
    "ax1.semilogx(results_df['lambda'], results_df['sparsity'] * 100, 'o-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Regularization Parameter λ', fontsize=12)\n",
    "ax1.set_ylabel('Sparsity (%)', fontsize=12)\n",
    "ax1.set_title('Sparsity vs Regularization', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: RMSE vs λ\n",
    "ax2.semilogx(results_df['lambda'], results_df['rmse'], 'o-', linewidth=2, markersize=8, color='orange')\n",
    "ax2.set_xlabel('Regularization Parameter λ', fontsize=12)\n",
    "ax2.set_ylabel('RMSE (dB)', fontsize=12)\n",
    "ax2.set_title('Prediction Error vs Regularization', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - As λ increases → sparsity increases (fewer transmitters)\")\n",
    "print(\"  - As λ increases → RMSE may increase (less flexible model)\")\n",
    "print(\"  - Optimal λ balances sparsity and accuracy\")\n",
    "print(\"  - Choose λ based on application requirements\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Summary and Key Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SPARSE RECONSTRUCTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n✓ Successfully localized {len(TRANSMITTERS)} transmitter(s) using sparse reconstruction\")\n",
    "print(f\"\\nKey Results:\")\n",
    "print(f\"  • Sparsity: {info_sparse['sparsity']*100:.2f}% ({info_sparse['n_nonzero']}/{np.prod(map_data['shape'])} non-zero)\")\n",
    "print(f\"  • Peak location: (row={info_sparse['peak_location'][0]}, col={info_sparse['peak_location'][1]})\")\n",
    "print(f\"  • Peak power: {info_sparse['peak_power_dBm']:.1f} dBm\")\n",
    "print(f\"  • Prediction RMSE: {rmse:.2f} dB\")\n",
    "print(f\"  • Computation time: {elapsed_time:.2f} seconds\")\n",
    "print(f\"  • Solver: {info_sparse['solver_info']['solver_used']}\")\n",
    "\n",
    "print(f\"\\nAdvantages of Sparse Reconstruction:\")\n",
    "print(f\"  1. Fast: ~10-30 seconds (vs. 5-10 minutes for likelihood-based)\")\n",
    "print(f\"  2. Sparse: Explicit localization with few non-zero entries\")\n",
    "print(f\"  3. Convex: Guaranteed global optimum\")\n",
    "print(f\"  4. Flexible: Tunable sparsity via λ parameter\")\n",
    "print(f\"  5. Physical: Non-negativity constraint ensures valid powers\")\n",
    "\n",
    "print(f\"\\nWhen to use this approach:\")\n",
    "print(f\"  • Single or few well-separated transmitters\")\n",
    "print(f\"  • Need for fast computation\")\n",
    "print(f\"  • Prior belief in sparse transmitter distribution\")\n",
    "print(f\"  • Want guaranteed global optimum (convex optimization)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional Experiments (Optional)\n",
    "\n",
    "Try these experiments to explore the algorithm further:\n",
    "\n",
    "1. **Change λ:** Modify `lambda_reg` to see how it affects sparsity vs accuracy\n",
    "2. **Different transmitters:** Change `TRANSMITTERS` list to analyze other bands\n",
    "3. **Solver comparison:** Force specific solvers ('cvxpy', 'sklearn', 'scipy') and compare\n",
    "4. **Path loss exponent:** Modify `np_exponent` to see sensitivity to propagation model\n",
    "5. **Different data:** Use different monitoring location configurations\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "**Documentation:**\n",
    "- `SPARSE_RECONSTRUCTION_THEORY.md` - Complete mathematical theory\n",
    "- `MATHEMATICAL_ANALYSIS.md` - Likelihood-based approach theory\n",
    "\n",
    "**Code Modules:**\n",
    "- `src/sparse_reconstruction/` - Sparse reconstruction implementation\n",
    "- `src/localization/` - Likelihood-based approach\n",
    "\n",
    "**Papers:**\n",
    "- Tibshirani (1996): \"Regression Shrinkage and Selection via the Lasso\"\n",
    "- Candès & Tao (2005): \"Decoding by Linear Programming\"\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (changen_env)",
   "language": "python",
   "name": "changen_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
