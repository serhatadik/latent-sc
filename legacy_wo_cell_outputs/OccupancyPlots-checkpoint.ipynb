{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a3269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def min_max_frequencies(monitor_foldername):\n",
    "    def read_gzipped_csv(file_path):\n",
    "        with gzip.open(file_path, 'rt') as file:\n",
    "            return pd.read_csv(file)\n",
    "\n",
    "    def extract_timestamp_from_filename(filename):\n",
    "        match = re.search(r'-(\\d+)\\.csv\\.gz$', filename)\n",
    "        return int(match.group(1)) if match else None\n",
    "\n",
    "    def concatenate_csvs_in_folder(folder_path):\n",
    "        dataframes = []\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.gz'):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                df = read_gzipped_csv(file_path)\n",
    "                timestamp = extract_timestamp_from_filename(filename)\n",
    "                df['timestamp'] = pd.to_datetime(timestamp, unit='s')\n",
    "                dataframes.append(df)\n",
    "        return pd.concat(dataframes, ignore_index=True) if dataframes else pd.DataFrame()\n",
    "\n",
    "    folder_path = './rfbaseline/' + monitor_foldername + \"/\"\n",
    "    combined_df = concatenate_csvs_in_folder(folder_path)\n",
    "\n",
    "    if not combined_df.empty:\n",
    "        min_frequency = combined_df['frequency'].min()\n",
    "        max_frequency = combined_df['frequency'].max()\n",
    "        return min_frequency, max_frequency\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Example usage\n",
    "monitor_foldername = 'Guesthouse'  # Replace with your folder name\n",
    "min_freq, max_freq = min_max_frequencies(monitor_foldername)\n",
    "if min_freq is not None and max_freq is not None:\n",
    "    print(f\"Minimum Frequency: {min_freq} MHz\")\n",
    "    print(f\"Maximum Frequency: {max_freq} MHz\")\n",
    "else:\n",
    "    print(\"No data available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def min_max_frequencies(monitor_foldername):\n",
    "    def read_gzipped_csv(file_path):\n",
    "        with gzip.open(file_path, 'rt') as file:\n",
    "            return pd.read_csv(file)\n",
    "\n",
    "    def extract_timestamp_from_filename(filename):\n",
    "        match = re.search(r'-(\\d+)\\.csv\\.gz$', filename)\n",
    "        return int(match.group(1)) if match else None\n",
    "\n",
    "    def concatenate_csvs_in_folder(folder_path):\n",
    "        dataframes = []\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.gz'):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                df = read_gzipped_csv(file_path)\n",
    "                timestamp = extract_timestamp_from_filename(filename)\n",
    "                df['timestamp'] = pd.to_datetime(timestamp, unit='s')\n",
    "                dataframes.append(df)\n",
    "        return pd.concat(dataframes, ignore_index=True) if dataframes else pd.DataFrame()\n",
    "\n",
    "    folder_path = './rfbaseline/' + monitor_foldername + \"/\"\n",
    "    combined_df = concatenate_csvs_in_folder(folder_path)\n",
    "\n",
    "    if not combined_df.empty:\n",
    "        min_frequency = combined_df['frequency'].min()\n",
    "        max_frequency = combined_df['frequency'].max()\n",
    "        print(combined_df['frequency'])\n",
    "        return min_frequency, max_frequency\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Example usage\n",
    "monitor_foldername = 'EBC'  # Replace with your folder name\n",
    "min_freq, max_freq = min_max_frequencies(monitor_foldername)\n",
    "if min_freq is not None and max_freq is not None:\n",
    "    print(f\"Minimum Frequency: {min_freq} MHz\")\n",
    "    print(f\"Maximum Frequency: {max_freq} MHz\")\n",
    "else:\n",
    "    print(\"No data available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def median_time_diff_between_folders(monitor_foldername):\n",
    "    def extract_timestamp_from_filename(filename):\n",
    "        # Extract the Unix timestamp using a regular expression\n",
    "        match = re.search(r'-(\\d+)\\.csv\\.gz$', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def calculate_median_time_difference(folder_path):\n",
    "        timestamps = []\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.gz'):\n",
    "                timestamp = extract_timestamp_from_filename(filename)\n",
    "                if timestamp is not None:\n",
    "                    timestamps.append(timestamp)\n",
    "\n",
    "        if timestamps:\n",
    "            timestamps.sort()\n",
    "            time_differences = np.diff(timestamps)\n",
    "            return np.median(time_differences) if time_differences.size > 0 else None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    folder_path = './rfbaseline/' + monitor_foldername + \"/\"\n",
    "    median_diff = calculate_median_time_difference(folder_path)\n",
    "\n",
    "    return median_diff\n",
    "\n",
    "# Example usage of the function\n",
    "median_diff = median_time_diff_between_folders(\"Garage\")/3600\n",
    "if median_diff is not None:\n",
    "    print(f\"Median Time Difference Between Consecutive Files: {median_diff} hours\")\n",
    "else:\n",
    "    print(\"No files to calculate median time difference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14549e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define time intervals and seasons\n",
    "intervals = {\n",
    "    'morning': ('04:00:00', '12:00:00'),\n",
    "    'afternoon': ('12:00:00', '20:00:00'),\n",
    "    'night': ('20:00:00', '04:00:00')\n",
    "}\n",
    "seasons = {\n",
    "    'spring': (3, 6),\n",
    "    'summer': (6, 9),\n",
    "    'autumn': (9, 12),\n",
    "    'winter': (0, 3)\n",
    "}\n",
    "\n",
    "# Function to read gzipped CSV files\n",
    "def read_gzipped_csv(file_path):\n",
    "    with gzip.open(file_path, 'rt') as file:\n",
    "        df = pd.read_csv(file)\n",
    "        return df\n",
    "\n",
    "# Function to extract timestamp from filename\n",
    "def extract_timestamp_from_filename(filename):\n",
    "    match = re.search(r'-(\\d+)\\.csv\\.gz$', filename)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Function to concatenate CSVs in a folder\n",
    "def concatenate_csvs_in_folder(folder_path):\n",
    "    dataframes = []\n",
    "    cutoff_date = pd.Timestamp('2023-01-01')\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.gz'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            timestamp = extract_timestamp_from_filename(filename)\n",
    "            df = read_gzipped_csv(file_path)\n",
    "            df['timestamp'] = pd.to_datetime(timestamp, unit='s')\n",
    "            df = df.dropna()\n",
    "            df = df[df['timestamp'] >= cutoff_date]\n",
    "            dataframes.append(df)\n",
    "\n",
    "    return pd.concat(dataframes, ignore_index=True) if dataframes else pd.DataFrame()\n",
    "\n",
    "# Function to calculate linearly varying threshold\n",
    "def linear_threshold(freq, start, end, threshold_start, threshold_end):\n",
    "    return threshold_start + ((threshold_end - threshold_start) * (freq - start) / (end - start))\n",
    "\n",
    "# Function to process data for a single monitor\n",
    "def process_monitor_data(monitor_foldername, threshold_start, threshold_end, band_start, band_end):\n",
    "    folder_path = './rfbaseline/' + monitor_foldername + \"/\"\n",
    "    combined_df = concatenate_csvs_in_folder(folder_path)\n",
    "\n",
    "    results = {'time_of_day': {}, 'season': {}}\n",
    "\n",
    "    # Time-of-Day Analysis\n",
    "    for period, (start_time, end_time) in intervals.items():\n",
    "        if period == 'night':\n",
    "            mask = ((combined_df['timestamp'].dt.time >= pd.to_datetime(start_time).time()) |\n",
    "                    (combined_df['timestamp'].dt.time < pd.to_datetime(end_time).time()))\n",
    "        else:\n",
    "            mask = ((combined_df['timestamp'].dt.time >= pd.to_datetime(start_time).time()) & \n",
    "                    (combined_df['timestamp'].dt.time < pd.to_datetime(end_time).time()))\n",
    "\n",
    "        dfs_period = combined_df.loc[mask]\n",
    "        dfs_period = dfs_period[(dfs_period['frequency'] >= band_start) & (dfs_period['frequency'] <= band_end)]\n",
    "\n",
    "        dfs_period['threshold'] = dfs_period['frequency'].apply(lambda freq: linear_threshold(freq, band_start, band_end, threshold_start, threshold_end))\n",
    "        occupied_df = dfs_period[dfs_period['power'] > dfs_period['threshold']]\n",
    "        \n",
    "        duty_cycle = len(occupied_df) / len(dfs_period) * 100 if len(dfs_period) > 0 else 0\n",
    "        avg_power_occupied = np.mean(occupied_df['power']) if not occupied_df.empty else 0\n",
    "        variance_power_occupied = np.var(occupied_df['power']) if not occupied_df.empty else 0\n",
    "\n",
    "        results['time_of_day'][period] = {\n",
    "            'Duty_Cycle': duty_cycle,\n",
    "            'Avg_Power_Occupied': avg_power_occupied,\n",
    "            'Variance_Power_Occupied': variance_power_occupied\n",
    "        }\n",
    "\n",
    "    # Season Analysis\n",
    "    for season, (start_month, end_month) in seasons.items():\n",
    "        mask = ((combined_df['timestamp'].dt.month >= start_month) &\n",
    "                (combined_df['timestamp'].dt.month < end_month))\n",
    "        df_season = combined_df.loc[mask]\n",
    "        df_season = df_season[(df_season['frequency'] >= band_start) & (df_season['frequency'] <= band_end)]\n",
    "\n",
    "        df_season['threshold'] = df_season['frequency'].apply(lambda freq: linear_threshold(freq, band_start, band_end, threshold_start, threshold_end))\n",
    "        occupied_df = df_season[df_season['power'] > df_season['threshold']]\n",
    "        \n",
    "        duty_cycle = len(occupied_df) / len(df_season) * 100 if len(df_season) > 0 else 0\n",
    "        avg_power_occupied = np.mean(occupied_df['power']) if not occupied_df.empty else 0\n",
    "        variance_power_occupied = np.var(occupied_df['power']) if not occupied_df.empty else 0\n",
    "\n",
    "        results['season'][season] = {\n",
    "            'Duty_Cycle': duty_cycle,\n",
    "            'Avg_Power_Occupied': avg_power_occupied,\n",
    "            'Variance_Power_Occupied': variance_power_occupied\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Main function to process all monitors and plot results\n",
    "def main():\n",
    "    sns.set_theme()\n",
    "    monitors = ['Bookstore', 'EBC', 'Guesthouse', 'Moran', 'WEB', 'Sagepoint', 'Law73', 'Humanities', 'Madsen', 'Garage']  # Add your monitor folder names here\n",
    "    threshold_start = -105  # Set your threshold start\n",
    "    threshold_end = -105  # Set your threshold end\n",
    "    band_start = 3610  # Set your band start\n",
    "    band_end = 3650  # Set your band end\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    # Process data for each monitor\n",
    "    for monitor in monitors:\n",
    "        all_results[monitor] = process_monitor_data(monitor, threshold_start, threshold_end, band_start, band_end)\n",
    "\n",
    "    # Plotting for both time-of-day and season analysis\n",
    "    fig, axs = plt.subplots(6, 1, figsize=(15, 30))  # Create 6 subplots vertically\n",
    "    fig.suptitle('RF Monitor Metrics at Different Times of Day and Seasons')\n",
    "\n",
    "    metrics = ['Duty_Cycle', 'Avg_Power_Occupied', 'Variance_Power_Occupied']\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        for monitor, results in all_results.items():\n",
    "            times_of_day = list(results['time_of_day'].keys())\n",
    "            values = [results['time_of_day'][time][metric] for time in times_of_day]\n",
    "            axs[idx].plot(times_of_day, values, label=monitor)\n",
    "\n",
    "        axs[idx].set_title(metric + ' (Time of Day)')\n",
    "        axs[idx].set_xlabel('Time of Day')\n",
    "        axs[idx].set_ylabel(metric)\n",
    "        axs[idx].legend()\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        for monitor, results in all_results.items():\n",
    "            season_names = list(results['season'].keys())\n",
    "            values = [results['season'][season][metric] for season in season_names]\n",
    "            axs[idx + 3].plot(season_names, values, label=monitor)\n",
    "\n",
    "        axs[idx + 3].set_title(metric + ' (Season)')\n",
    "        axs[idx + 3].set_xlabel('Season')\n",
    "        axs[idx + 3].set_ylabel(metric)\n",
    "        axs[idx + 3].legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to make room for the main title\n",
    "    plt.show()\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_results = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"monitoring_metrics_day_season_36103650.npy\", all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e803207",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_dummy = np.load(\"monitoring_metrics_day_season.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf1f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a398c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e654b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "custom = {\"axes.edgecolor\": \"black\"}\n",
    "sns.set_style(\"whitegrid\", rc = custom)\n",
    "# Increase global font size\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20, 15))  # Create 6 subplots vertically\n",
    "fig.suptitle('RF Monitor Metrics at Different Times of Day and Seasons, 3610-3650 MHz', fontsize=30)\n",
    "\n",
    "metrics = ['Avg_Power_Occupied','Duty_Cycle', 'Variance_Power_Occupied']\n",
    "metric_units = ['dBX','Percentage','dBX$^2$']\n",
    "metric_labels = ['Average Occupancy Power','Duty Cycle','Signal Variance']\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']  # Add more colors if needed\n",
    "\n",
    "# Store legend labels and lines\n",
    "legend_labels = []\n",
    "legend_lines = []\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    for monitor_idx, (monitor, results) in enumerate(all_results.items()):\n",
    "        times_of_day = list(results['time_of_day'].keys())\n",
    "        values = [results['time_of_day'][time][metric] for time in times_of_day]\n",
    "        line, = axs[0, idx].plot(times_of_day, values, color=colors[monitor_idx], linewidth=2, linestyle='solid')\n",
    "        if idx == 0:  # Add legend items only once\n",
    "            legend_labels.append(monitor)\n",
    "            legend_lines.append(line)\n",
    "\n",
    "    axs[0, idx].set_title(metric_labels[idx] + ' (Time of Day)', fontsize=20)\n",
    "    axs[0, idx].set_xlabel('Time of Day', fontsize=18)\n",
    "    axs[0, idx].set_ylabel(metric_units[idx], fontsize=18)\n",
    "    axs[0, idx].grid(True)\n",
    "\n",
    "    # Adjust tick parameters\n",
    "    axs[0, idx].tick_params(axis='both', labelsize=16)\n",
    "    axs[0, idx].text(-0.1, 1.1, f'({chr(97 + idx)})', transform=axs[0, idx].transAxes, fontsize=20, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "\n",
    "# Add legend for the top row\n",
    "fig.legend(legend_lines, legend_labels, loc='lower center', ncol=len(legend_labels), fontsize=16, bbox_to_anchor=(0.5, 0.905))\n",
    "\n",
    "# Clear legend lines and labels for the bottom row\n",
    "legend_lines.clear()\n",
    "legend_labels.clear()\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    for monitor_idx, (monitor, results) in enumerate(all_results.items()):\n",
    "        season_names = list(results['season'].keys())\n",
    "        values = [results['season'][season][metric] for season in season_names]\n",
    "        line, = axs[1, idx].plot(season_names, values, color=colors[monitor_idx], linewidth=2, linestyle='dashed')\n",
    "        if idx == 0:  # Add legend items only once\n",
    "            legend_labels.append(monitor)\n",
    "            legend_lines.append(line)\n",
    "\n",
    "    axs[1, idx].set_title(metric_labels[idx] + ' (Season)', fontsize=20)\n",
    "    axs[1, idx].set_xlabel('Season', fontsize=18)\n",
    "    axs[1, idx].set_ylabel(metric_units[idx], fontsize=18)\n",
    "    axs[1, idx].grid(True)\n",
    "\n",
    "    # Adjust tick parameters\n",
    "    axs[1, idx].tick_params(axis='both', labelsize=16)\n",
    "    axs[1, idx].text(-0.1, 1.1, f'({chr(100 + idx)})', transform=axs[1, idx].transAxes, fontsize=20, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "    \n",
    "\n",
    "# Add legend for the bottom row\n",
    "fig.legend(legend_lines, legend_labels, loc='lower center', ncol=len(legend_labels), fontsize=16, bbox_to_anchor=(0.5, 0.04))\n",
    "\n",
    "# Adjust layout to make room for the main title, legends and improve spacing\n",
    "plt.tight_layout(rect=[0, 0.08, 1, 0.95])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e052fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the time intervals\n",
    "intervals = {\n",
    "    'morning': ('04:00:00', '12:00:00'),\n",
    "    'afternoon': ('12:00:00', '20:00:00'),\n",
    "    'night': ('20:00:00', '04:00:00')\n",
    "}\n",
    "\n",
    "# Function to read gzipped CSV files\n",
    "def read_gzipped_csv(file_path):\n",
    "    with gzip.open(file_path, 'rt') as file:\n",
    "        df = pd.read_csv(file)\n",
    "        return df\n",
    "\n",
    "# Function to extract timestamp from filename\n",
    "def extract_timestamp_from_filename(filename):\n",
    "    match = re.search(r'-(\\d+)\\.csv\\.gz$', filename)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Function to concatenate CSVs in a folder\n",
    "def concatenate_csvs_in_folder(folder_path):\n",
    "    dataframes = []\n",
    "    cutoff_date = pd.Timestamp('2023-01-01')\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.gz'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            timestamp = extract_timestamp_from_filename(filename)\n",
    "            df = read_gzipped_csv(file_path)\n",
    "            df['timestamp'] = pd.to_datetime(timestamp, unit='s')\n",
    "            df = df.dropna()\n",
    "            df = df[df['timestamp'] >= cutoff_date]\n",
    "            dataframes.append(df)\n",
    "\n",
    "    return pd.concat(dataframes, ignore_index=True) if dataframes else pd.DataFrame()\n",
    "\n",
    "# Function to calculate linearly varying threshold\n",
    "def linear_threshold(freq, start, end, threshold_start, threshold_end):\n",
    "    return threshold_start + ((threshold_end - threshold_start) * (freq - start) / (end - start))\n",
    "\n",
    "# Function to process data for a single monitor\n",
    "def process_monitor_data(monitor_foldername, threshold_start, threshold_end, band_start, band_end):\n",
    "    folder_path = './rfbaseline/' + monitor_foldername + \"/\"\n",
    "    combined_df = concatenate_csvs_in_folder(folder_path)\n",
    "\n",
    "    results = {}\n",
    "    for period, (start_time, end_time) in intervals.items():\n",
    "        if period == 'night':\n",
    "            mask = ((combined_df['timestamp'].dt.time >= pd.to_datetime(start_time).time()) |\n",
    "                    (combined_df['timestamp'].dt.time < pd.to_datetime(end_time).time()))\n",
    "        else:\n",
    "            mask = ((combined_df['timestamp'].dt.time >= pd.to_datetime(start_time).time()) & \n",
    "                    (combined_df['timestamp'].dt.time < pd.to_datetime(end_time).time()))\n",
    "\n",
    "        dfs_period = combined_df.loc[mask]\n",
    "        dfs_period = dfs_period[(dfs_period['frequency'] >= band_start) & (dfs_period['frequency'] <= band_end)]\n",
    "\n",
    "        dfs_period['threshold'] = dfs_period['frequency'].apply(lambda freq: linear_threshold(freq, band_start, band_end, threshold_start, threshold_end))\n",
    "        occupied_df = dfs_period[dfs_period['power'] > dfs_period['threshold']]\n",
    "        \n",
    "        duty_cycle = len(occupied_df) / len(dfs_period) * 100 if len(dfs_period) > 0 else 0\n",
    "        avg_power_occupied = np.mean(occupied_df['power']) if not occupied_df.empty else 0\n",
    "        variance_power_occupied = np.var(occupied_df['power']) if not occupied_df.empty else 0\n",
    "\n",
    "        results[period] = {\n",
    "            'Duty_Cycle': duty_cycle,\n",
    "            'Avg_Power_Occupied': avg_power_occupied,\n",
    "            'Variance_Power_Occupied': variance_power_occupied\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Main function to process all monitors and plot results\n",
    "def main():\n",
    "    sns.set_theme()\n",
    "    monitors = ['Bookstore', 'EBC', 'Guesthouse', 'Moran', 'WEB', 'Sagepoint', 'Law73', 'Humanities', 'Madsen', 'Garage']  # Add your monitor folder names here\n",
    "    threshold_start = -105  # Set your threshold start\n",
    "    threshold_end = -105  # Set your threshold end\n",
    "    band_start = 3470  # Set your band start\n",
    "    band_end = 3510  # Set your band end\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    # Process data for each monitor\n",
    "    for monitor in monitors:\n",
    "        all_results[monitor] = process_monitor_data(monitor, threshold_start, threshold_end, band_start, band_end)\n",
    "\n",
    "    # Set up the subplot figure\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(12, 18))  # Create 3 subplots vertically\n",
    "    fig.suptitle('RF Monitor Metrics at Different Times of Day')\n",
    "\n",
    "    metrics = ['Duty_Cycle', 'Avg_Power_Occupied', 'Variance_Power_Occupied']\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        for monitor, results in all_results.items():\n",
    "            times_of_day = list(results.keys())\n",
    "            values = [results[time][metric] for time in times_of_day]\n",
    "            axs[idx].plot(times_of_day, values, label=monitor)\n",
    "\n",
    "        axs[idx].set_title(metric)\n",
    "        axs[idx].set_xlabel('Time of Day')\n",
    "        axs[idx].set_ylabel(metric)\n",
    "        axs[idx].legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to make room for the main title\n",
    "    plt.show()\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_results = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for monitor, results in all_results.items():\n",
    "        times_of_day = list(results.keys())\n",
    "        values = [results[time][metric] for time in times_of_day]\n",
    "        plt.plot(times_of_day, values, label=monitor)\n",
    "\n",
    "    plt.title(f'{metric} for Each Monitor at Different Times of Day')\n",
    "    plt.xlabel('Time of Day')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc41528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "def occupancy(monitor_foldername, threshold_start, threshold_end, band_start, band_end):\n",
    "    sns.set_theme()\n",
    "\n",
    "    def read_gzipped_csv(file_path):\n",
    "        with gzip.open(file_path, 'rt') as file:\n",
    "            df = pd.read_csv(file)\n",
    "            return df\n",
    "\n",
    "\n",
    "    def extract_timestamp_from_filename(filename):\n",
    "        # Extract the Unix timestamp using a regular expression\n",
    "        match = re.search(r'-(\\d+)\\.csv\\.gz$', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def concatenate_csvs_in_folder(folder_path):\n",
    "        dataframes = []\n",
    "        cutoff_date = pd.Timestamp('2023-01-01')  # Set the cutoff date to Jan 1, 2023\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.gz'):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                timestamp = extract_timestamp_from_filename(filename)\n",
    "                df = read_gzipped_csv(file_path)\n",
    "                df['timestamp'] = pd.to_datetime(timestamp, unit='s')  # Convert timestamp to datetime\n",
    "\n",
    "                # Drop rows with NaN values\n",
    "                df = df.dropna()\n",
    "                # Filter out rows older than June 2022\n",
    "                df = df[df['timestamp'] >= cutoff_date]\n",
    "\n",
    "                dataframes.append(df)\n",
    "\n",
    "        # Concatenate all dataframes into a single dataframe\n",
    "        if dataframes:\n",
    "            return pd.concat(dataframes, ignore_index=True)\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "\n",
    "    # Example usage\n",
    "    folder_path = './rfbaseline/'+monitor_foldername+\"/\"\n",
    "    combined_df = concatenate_csvs_in_folder(folder_path)\n",
    "    #print(np.unique(combined_df[\"timestamp\"]))\n",
    "    combined_df = combined_df.drop(columns=['center_freq'])\n",
    "\n",
    "\n",
    "    # Assuming combined_df is your DataFrame\n",
    "\n",
    "\n",
    "    #df = combined_df.groupby('frequency')['power'].apply(avg_pow).reset_index()\n",
    "\n",
    "    # Define the start and end of the CBRS band (in MHz)\n",
    "    #band_start = 3470\n",
    "    #band_end = 3510\n",
    "\n",
    "    # Example usage\n",
    "    folder_path = './rfbaseline/'+monitor_foldername+\"/\"\n",
    "    combined_df = concatenate_csvs_in_folder(folder_path)\n",
    "    combined_df = combined_df.drop(columns=['center_freq'])\n",
    "\n",
    "    # Define the start and end of the CBRS band (in MHz)\n",
    "    chunk_size = 1 #np.round((band_end-band_start)/100)  # in MHz\n",
    "\n",
    "    # Initialize a list to store the aggregate results\n",
    "    aggregate_results = []\n",
    "\n",
    "    def linear_threshold(freq, start, end, threshold_start, threshold_end):\n",
    "        \"\"\"Calculate linearly varying threshold.\"\"\"\n",
    "        return threshold_start + ((threshold_end - threshold_start) * (freq - start) / (end - start))\n",
    "\n",
    "    # Iterate over the frequency band in chunks\n",
    "    for start in range(band_start, band_end, chunk_size):\n",
    "        end = start + chunk_size\n",
    "        chunk_df = combined_df[(combined_df['frequency'] >= start) & (combined_df['frequency'] <= end)]\n",
    "\n",
    "        # Calculate mean and standard deviation in the linear domain\n",
    "        mean_power_db = np.mean(chunk_df['power'])\n",
    "        std_power_db = np.std(chunk_df['power'])\n",
    "\n",
    "        # Calculate the dynamic threshold for the chunk\n",
    "        chunk_threshold = linear_threshold((start+end)/2, band_start, band_end, threshold_start, threshold_end)\n",
    "        print(chunk_threshold)\n",
    "        # Calculate the duty cycle and average power when occupied\n",
    "        occupied_df = chunk_df[chunk_df['power'] > chunk_threshold]\n",
    "        duty_cycle = len(occupied_df) / len(chunk_df) * 100\n",
    "        avg_power_occupied = np.mean(occupied_df['power']) if not occupied_df.empty else np.nan\n",
    "        variance_power_occupied = np.var(occupied_df['power']) if not occupied_df.empty else np.nan\n",
    "\n",
    "        # Store the results for the current chunk\n",
    "        aggregate_results.append({\n",
    "            'Chunk_Start': start,\n",
    "            'Chunk_End': end,\n",
    "            'Mean': mean_power_db,\n",
    "            'Std': std_power_db,\n",
    "            'Threshold': chunk_threshold,\n",
    "            'Duty_Cycle': duty_cycle,\n",
    "            'Avg_Power_Occupied': avg_power_occupied,\n",
    "            'Variance_Power_Occupied': variance_power_occupied\n",
    "        })\n",
    "\n",
    "    # Rest of the code for aggregating results and plotting...\n",
    "\n",
    "    \n",
    "    # Convert the list of dicts to a DataFrame\n",
    "    aggregate_results_df = pd.DataFrame(aggregate_results)\n",
    "\n",
    "    # Aggregate the results\n",
    "    # You can choose how to aggregate, here's a simple mean aggregation\n",
    "    final_mean_threshold = aggregate_results_df['Threshold'].mean()\n",
    "    final_duty_cycle = aggregate_results_df['Duty_Cycle'].mean()\n",
    "    final_avg_power_occupied = aggregate_results_df['Avg_Power_Occupied'].mean()\n",
    "    final_variance_power_occupied = aggregate_results_df['Variance_Power_Occupied'].mean()\n",
    "\n",
    "    print(aggregate_results_df)\n",
    "    print(f\"Final Mean Threshold: {final_mean_threshold}\")\n",
    "    print(f\"Final Duty Cycle: {final_duty_cycle}\")\n",
    "    print(f\"Final Average Power Occupied: {final_avg_power_occupied}\")\n",
    "    print(f\"Final Variance of Power Occupied: {final_variance_power_occupied}\")\n",
    "\n",
    "\n",
    "    # Filter rows where frequency is between band start and ends\n",
    "    \n",
    "    ## 3350-3400\n",
    "    #filtered_df = combined_df[(combined_df['frequency'] >= band_start) & (combined_df['frequency'] <= band_end)& ((combined_df['frequency'] <= 3358.5) | (combined_df['frequency'] >= 3361)) & ((combined_df['frequency'] <= 3383) | (combined_df['frequency'] >= 3385.5))]\n",
    "    \n",
    "    ## 3470-3520\n",
    "    filtered_df = combined_df[(combined_df['frequency'] >= band_start) & (combined_df['frequency'] <= band_end)]\n",
    "\n",
    "\n",
    "    # Calculate the linearly varying threshold for each frequency\n",
    "    filtered_df['threshold'] = filtered_df['frequency'].apply(lambda freq: linear_threshold(freq, band_start, band_end, threshold_start, threshold_end))\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    plt.scatter(filtered_df[\"frequency\"], filtered_df[\"power\"], marker=\"*\", s=0.3)\n",
    "    frequencies = np.linspace(band_start, band_end, 500)  # Generate frequency points\n",
    "    thresholds = [linear_threshold(freq, band_start, band_end, threshold_start, threshold_end) for freq in frequencies]\n",
    "    plt.plot(frequencies, thresholds, 'r--', label='Threshold')  # Plot threshold line\n",
    "\n",
    "    # Setting labels, title, and legend\n",
    "    plt.xlabel(\"Frequency (MHz)\")\n",
    "    plt.ylabel(\"Power (dB)\")\n",
    "    plt.title(\"Monitor @\"+monitor_foldername)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel(\"Frequency (MHz)\")\n",
    "    plt.ylabel(\"Power (dB)\")\n",
    "    plt.title(\"Monitor @\"+monitor_foldername)\n",
    "    plt.show()\n",
    "\n",
    "    # Count the number of rows above their respective power threshold\n",
    "    occupied_count = filtered_df[filtered_df['power'] > filtered_df['threshold']].shape[0]\n",
    "\n",
    "    # Calculate the total number of rows in the filtered DataFrame\n",
    "    total_count = filtered_df.shape[0]\n",
    "\n",
    "    # Calculate the duty cycle\n",
    "    duty_cycle = (occupied_count / total_count) * 100\n",
    "\n",
    "    print(duty_cycle)\n",
    "    matplotlib.rcParams['font.family'] = 'Times New Roman'\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    plt.hist(filtered_df[\"power\"], bins=30, color='green')\n",
    "    plt.ylabel(\"Count\", fontsize=20)\n",
    "    plt.xlabel(\"Power [dBX]\", fontsize=20)\n",
    "    plt.title(str(band_start) + \"-\" + str(band_end) + \" MHz Power Histogram @ \"+monitor_foldername, fontsize=24)\n",
    "    #ax.set_xticklabels(fontsize=14, rotation=0)\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    #plt.axvline(x=threshold, color='red', linestyle='dashed')\n",
    "    #plt.text(threshold + 0.5, plt.ylim()[1] * 0.75, 'Threshold', color='red', fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b395e3",
   "metadata": {},
   "source": [
    "### Functional Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff27aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "def occupancy(monitor_foldername, threshold, band_start, band_end):\n",
    "    sns.set_theme()\n",
    "\n",
    "    def read_gzipped_csv(file_path):\n",
    "        with gzip.open(file_path, 'rt') as file:\n",
    "            df = pd.read_csv(file)\n",
    "            return df\n",
    "\n",
    "\n",
    "    def extract_timestamp_from_filename(filename):\n",
    "        # Extract the Unix timestamp using a regular expression\n",
    "        match = re.search(r'-(\\d+)\\.csv\\.gz$', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def concatenate_csvs_in_folder(folder_path):\n",
    "        dataframes = []\n",
    "        cutoff_date = pd.Timestamp('2023-01-01')  # Set the cutoff date to Jan 1, 2023\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.gz'):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                timestamp = extract_timestamp_from_filename(filename)\n",
    "                df = read_gzipped_csv(file_path)\n",
    "                df['timestamp'] = pd.to_datetime(timestamp, unit='s')  # Convert timestamp to datetime\n",
    "\n",
    "                # Drop rows with NaN values\n",
    "                df = df.dropna()\n",
    "                # Filter out rows older than June 2022\n",
    "                df = df[df['timestamp'] >= cutoff_date]\n",
    "\n",
    "                dataframes.append(df)\n",
    "\n",
    "        # Concatenate all dataframes into a single dataframe\n",
    "        if dataframes:\n",
    "            return pd.concat(dataframes, ignore_index=True)\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "\n",
    "    # Example usage\n",
    "    folder_path = './rfbaseline/'+monitor_foldername+\"/\"\n",
    "    combined_df = concatenate_csvs_in_folder(folder_path)\n",
    "    #print(np.unique(combined_df[\"timestamp\"]))\n",
    "    combined_df = combined_df.drop(columns=['center_freq'])\n",
    "\n",
    "\n",
    "    # Assuming combined_df is your DataFrame\n",
    "\n",
    "\n",
    "    #df = combined_df.groupby('frequency')['power'].apply(avg_pow).reset_index()\n",
    "\n",
    "    # Define the start and end of the CBRS band (in MHz)\n",
    "    #band_start = 3470\n",
    "    #band_end = 3510\n",
    "    chunk_size = band_end-band_start  # in MHz\n",
    "\n",
    "    # Initialize a list to store the aggregate results\n",
    "    aggregate_results = []\n",
    "\n",
    "    # Iterate over the frequency band in chunks of 25 MHz\n",
    "    for start in range(band_start, band_end, chunk_size):\n",
    "        end = start + chunk_size\n",
    "        # Filter the DataFrame for the current chunk\n",
    "        ## 3350-3400\n",
    "        #chunk_df = combined_df[(combined_df['frequency'] >= start) & (combined_df['frequency'] < end)& ((combined_df['frequency'] <= 3358.5) | (combined_df['frequency'] >= 3361)) & ((combined_df['frequency'] <= 3383) | (combined_df['frequency'] >= 3385))]\n",
    "        \n",
    "        ## 3470-3520\n",
    "        chunk_df = combined_df[(combined_df['frequency'] >= start) & (combined_df['frequency'] <= end)]\n",
    "\n",
    "        # Calculate mean and standard deviation in the linear domain\n",
    "        mean_power_db = np.mean(chunk_df['power'])\n",
    "        std_power_db = np.std(chunk_df['power'])\n",
    "\n",
    "        # Set the threshold to mean + 1 standard deviation\n",
    "        #threshold = -145\n",
    "\n",
    "        # Calculate the duty cycle and average power when occupied\n",
    "        occupied_df = chunk_df[chunk_df['power'] > threshold]\n",
    "        duty_cycle = len(occupied_df) / len(chunk_df) * 100\n",
    "        avg_power_occupied = np.mean(occupied_df['power']) if not occupied_df.empty else np.nan\n",
    "        variance_power_occupied = np.var(occupied_df['power']) if not occupied_df.empty else np.nan\n",
    "\n",
    "        # Store the results for the current chunk\n",
    "        aggregate_results.append({\n",
    "            'Chunk_Start': start,\n",
    "            'Chunk_End': end,\n",
    "            'Mean': mean_power_db,\n",
    "            'Std': std_power_db,\n",
    "            'Threshold': threshold,\n",
    "            'Duty_Cycle': duty_cycle,\n",
    "            'Avg_Power_Occupied': avg_power_occupied,\n",
    "            'Variance_Power_Occupied': variance_power_occupied  # Added variance calculation\n",
    "        })\n",
    "\n",
    "    # Convert the list of dicts to a DataFrame\n",
    "    aggregate_results_df = pd.DataFrame(aggregate_results)\n",
    "\n",
    "    # Aggregate the results\n",
    "    # You can choose how to aggregate, here's a simple mean aggregation\n",
    "    final_mean_threshold = aggregate_results_df['Threshold'].mean()\n",
    "    final_duty_cycle = aggregate_results_df['Duty_Cycle'].mean()\n",
    "    final_avg_power_occupied = aggregate_results_df['Avg_Power_Occupied'].mean()\n",
    "    final_variance_power_occupied = aggregate_results_df['Variance_Power_Occupied'].mean()\n",
    "\n",
    "    print(aggregate_results_df)\n",
    "    print(f\"Final Mean Threshold: {final_mean_threshold}\")\n",
    "    print(f\"Final Duty Cycle: {final_duty_cycle}\")\n",
    "    print(f\"Final Average Power Occupied: {final_avg_power_occupied}\")\n",
    "    print(f\"Final Variance of Power Occupied: {final_variance_power_occupied}\")\n",
    "\n",
    "\n",
    "    # Filter rows where frequency is between band start and ends\n",
    "    \n",
    "    ## 3350-3400\n",
    "    #filtered_df = combined_df[(combined_df['frequency'] >= band_start) & (combined_df['frequency'] <= band_end)& ((combined_df['frequency'] <= 3358.5) | (combined_df['frequency'] >= 3361)) & ((combined_df['frequency'] <= 3383) | (combined_df['frequency'] >= 3385.5))]\n",
    "    \n",
    "    ## 3470-3520\n",
    "    filtered_df = combined_df[(combined_df['frequency'] >= band_start) & (combined_df['frequency'] <= band_end)]\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    plt.scatter(filtered_df[\"frequency\"], filtered_df[\"power\"], marker=\"*\", s=0.3)\n",
    "    plt.xlabel(\"Frequency (MHz)\")\n",
    "    plt.ylabel(\"Power (dB)\")\n",
    "    plt.title(\"Monitor @\"+monitor_foldername)\n",
    "    plt.show()\n",
    "    # Define a power threshold, for example, -90 dB\n",
    "    power_threshold = threshold\n",
    "\n",
    "    # Count the number of rows above the power threshold\n",
    "    occupied_count = filtered_df[filtered_df['power'] > power_threshold].shape[0]\n",
    "\n",
    "    # Calculate the total number of rows in the filtered DataFrame\n",
    "    total_count = filtered_df.shape[0]\n",
    "\n",
    "    # Calculate the duty cycle\n",
    "    duty_cycle = (occupied_count / total_count) * 100\n",
    "\n",
    "    print(duty_cycle)\n",
    "    matplotlib.rcParams['font.family'] = 'Times New Roman'\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    plt.hist(filtered_df[\"power\"], bins=30, color='green')\n",
    "    plt.ylabel(\"Count\", fontsize=20)\n",
    "    plt.xlabel(\"Power [dBX]\", fontsize=20)\n",
    "    plt.title(str(band_start) + \"-\" + str(band_end) + \" MHz Power Histogram @ \"+monitor_foldername, fontsize=24)\n",
    "    #ax.set_xticklabels(fontsize=14, rotation=0)\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    plt.axvline(x=threshold, color='red', linestyle='dashed')\n",
    "    plt.text(threshold + 0.5, plt.ylim()[1] * 0.75, 'Threshold', color='red', fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Bookstore\", -105, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e931f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "occupancy(\"EBC\", -105, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65eb6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Guesthouse\", -105, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3939d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "occupancy(\"Moran\", -105, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e919de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"WEB\", -105, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22300dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Sagepoint\", -105, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564e4f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "occupancy(\"Law73\", -105, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Humanities\", -105, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Madsen\", -105, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07195039",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Garage\", -105, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6bb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Bookstore\", -105, 3610, 3650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"EBC\", -105, 3610, 3650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc84217",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Guesthouse\", -105, 3610, 3650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f257622",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Moran\", -105, 3610, 3650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"WEB\", -105, 3610, 3650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfaaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Sagepoint\", -105, 3610, 3650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05424a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Law73\", -105, 3610, 3650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25eee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Humanities\", -105, 3610, 3650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3050e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Madsen\", -105, 3610, 3650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc33d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Garage\", -105, 3610, 3650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d0a4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "occupancy(\"Bookstore\", -100, -90, 2504, 2544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eefb00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"EBC\", -100, -90, 2504, 2544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e703df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Guesthouse\", -100, -90, 2504,2544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Moran\", -100, -90, 2504, 2544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5f8a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "occupancy(\"WEB\", -100, -90, 2504, 2544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c55d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Sagepoint\", -100, -90, 2504, 2544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Law73\", -100, -90, 2504, 2544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Humanities\", -100, -90, 2504, 2544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c5ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Madsen\", -100, -90, 2504, 2544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Garage\", -100, -90, 2504, 2544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b14717c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a455e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94520907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba5a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2957ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_dict = {\"Bookstore\": [45.00, -89.90], \"EBC\": [89.79, -94.60], \"Guesthouse\":[76.90, -99.32], \"Moran\":[21.23, -101.14], \"WEB\": [42.88, -91.95], \"Sagepoint\": [56.00, -98.58], \"Law73\":[44.92, -86.17], \"Humanities\": [71.66, -97.28], \"Madsen\":[44.29, -100.86], \"Garage\": [99.00, -87.82]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddd319",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy(\"Madsen\", -106, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49bbfa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "occupancy(\"Garage\", -106, 3470, 3510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9970f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def occupancy2(monitor_foldername):\n",
    "    sns.set_theme()\n",
    "\n",
    "    def read_gzipped_csv(file_path):\n",
    "        with gzip.open(file_path, 'rt') as file:\n",
    "            df = pd.read_csv(file)\n",
    "            return df\n",
    "\n",
    "\n",
    "    def extract_timestamp_from_filename(filename):\n",
    "        # Extract the Unix timestamp using a regular expression\n",
    "        match = re.search(r'-(\\d+)\\.csv\\.gz$', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "    def concatenate_csvs_in_folder(folder_path):\n",
    "        dataframes_dict = {}\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.gz'):\n",
    "                # Extract the base name before \"_\"\n",
    "                base_name = filename.split('_')[0]\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                timestamp = extract_timestamp_from_filename(filename)\n",
    "                df = read_gzipped_csv(file_path)\n",
    "                df['timestamp'] = timestamp\n",
    "\n",
    "                # Append the dataframe to the list in the dictionary for the base name\n",
    "                if base_name not in dataframes_dict:\n",
    "                    dataframes_dict[base_name] = []\n",
    "                dataframes_dict[base_name].append(df)\n",
    "\n",
    "        # Concatenate dataframes in the dictionary and store them in a new dictionary\n",
    "        concatenated_dfs = {}\n",
    "        for base_name, dfs in dataframes_dict.items():\n",
    "            if dfs:\n",
    "                concatenated_dfs[base_name] = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        return concatenated_dfs\n",
    "\n",
    "\n",
    "    # Example usage\n",
    "    folder_path = './rfbaseline/'+monitor_foldername+\"/\"\n",
    "    combined_df = concatenate_csvs_in_folder(folder_path)\n",
    "    print(combined_df)\n",
    "    \n",
    "    for key in combined_df.keys():\n",
    "        occupancy3(combined_df[key], key)\n",
    "    \n",
    "\n",
    "occupancy2(\"Emulab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f18b76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def occupancy2(monitor_foldername):\n",
    "    sns.set_theme()\n",
    "\n",
    "    def read_gzipped_csv(file_path, band_start, band_end):\n",
    "        with gzip.open(file_path, 'rt') as file:\n",
    "            df = pd.read_csv(file)\n",
    "            # Filter out frequencies outside the band range\n",
    "            return df[(df['frequency'] >= band_start) & (df['frequency'] <= band_end)]\n",
    "\n",
    "    def extract_timestamp_from_filename(filename):\n",
    "        match = re.search(r'-(\\d+)\\.csv\\.gz$', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def concatenate_csvs_in_folder(folder_path, band_start, band_end):\n",
    "        dataframes_dict = {}\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.gz'):\n",
    "                base_name = filename.split('_')[0]\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                timestamp = extract_timestamp_from_filename(filename)\n",
    "                df = read_gzipped_csv(file_path, band_start, band_end)\n",
    "                df['timestamp'] = timestamp\n",
    "\n",
    "                if base_name not in dataframes_dict:\n",
    "                    dataframes_dict[base_name] = []\n",
    "                dataframes_dict[base_name].append(df)\n",
    "\n",
    "        concatenated_dfs = {}\n",
    "        for base_name, dfs in dataframes_dict.items():\n",
    "            if dfs:\n",
    "                concatenated_dfs[base_name] = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        return concatenated_dfs\n",
    "\n",
    "    # Define the start and end of the band (in MHz)\n",
    "    band_start = 3550\n",
    "    band_end = 3600\n",
    "\n",
    "    folder_path = './rfbaseline/' + monitor_foldername + \"/\"\n",
    "    combined_df = concatenate_csvs_in_folder(folder_path, band_start, band_end)\n",
    "    for key in combined_df.keys():\n",
    "        print(len(combined_df[key]))\n",
    "        occupancy3(combined_df[key], key)\n",
    "\n",
    "def occupancy3(df_, node_name):\n",
    "    def avg_pow(powers):\n",
    "        pow_mean = np.mean(powers)\n",
    "        return pow_mean\n",
    "\n",
    "    df_ = df_.drop(columns=['center_freq'])\n",
    "\n",
    "    df = df_.groupby('frequency')['power'].apply(avg_pow).reset_index()\n",
    "\n",
    "    # Define the start and end of the CBRS band (in MHz)\n",
    "    band_start = 3550\n",
    "    band_end = 3600\n",
    "    chunk_size = 50  # in MHz\n",
    "\n",
    "    aggregate_results = []\n",
    "\n",
    "    for start in range(band_start, band_end, chunk_size):\n",
    "        end = start + chunk_size\n",
    "        chunk_df = df[(df['frequency'] >= start) & (df['frequency'] < end)]\n",
    "\n",
    "        mean_power_db = np.mean(chunk_df['power'])\n",
    "        std_power_db = np.std(chunk_df['power'])\n",
    "\n",
    "        threshold = -138\n",
    "\n",
    "        occupied_df = chunk_df[chunk_df['power'] > threshold]\n",
    "        duty_cycle = len(occupied_df) / len(chunk_df) * 100\n",
    "        avg_power_occupied = avg_pow(occupied_df['power']) if not occupied_df.empty else np.nan\n",
    "\n",
    "        aggregate_results.append({\n",
    "            'Chunk_Start': start,\n",
    "            'Chunk_End': end,\n",
    "            'Mean': mean_power_db,\n",
    "            'Std': std_power_db,\n",
    "            'Threshold': threshold,\n",
    "            'Duty_Cycle': duty_cycle,\n",
    "            'Avg_Power_Occupied': avg_power_occupied\n",
    "        })\n",
    "\n",
    "    aggregate_results_df = pd.DataFrame(aggregate_results)\n",
    "\n",
    "    final_mean_threshold = aggregate_results_df['Threshold'].mean()\n",
    "    final_duty_cycle = aggregate_results_df['Duty_Cycle'].mean()\n",
    "    final_avg_power_occupied = aggregate_results_df['Avg_Power_Occupied'].mean()\n",
    "\n",
    "    print(aggregate_results_df)\n",
    "    print(f\"Final Mean Threshold: {final_mean_threshold}\")\n",
    "    print(f\"Final Duty Cycle: {final_duty_cycle}\")\n",
    "    print(f\"Final Average Power Occupied: {final_avg_power_occupied}\")\n",
    "\n",
    "    filtered_df = df[(df['frequency'] >= band_start) & (df['frequency'] <= band_end)]\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    plt.scatter(filtered_df[\"frequency\"], filtered_df[\"power\"], marker=\"*\", s=0.3)\n",
    "    plt.xlabel(\"Frequency (MHz)\")\n",
    "    plt.ylabel(\"Power (dB)\")\n",
    "    plt.title(\"Monitor @\" + node_name)\n",
    "    plt.show()\n",
    "    # Define a power threshold, for example, -90 dB\n",
    "    power_threshold = threshold\n",
    "\n",
    "    # Count the number of rows above the power threshold\n",
    "    occupied_count = filtered_df[filtered_df['power'] > power_threshold].shape[0]\n",
    "\n",
    "    # Calculate the total number of rows in the filtered DataFrame\n",
    "    total_count = filtered_df.shape[0]\n",
    "\n",
    "    # Calculate the duty cycle\n",
    "    duty_cycle = (occupied_count / total_count) * 100\n",
    "\n",
    "    print(duty_cycle)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(filtered_df[\"power\"], bins=20)\n",
    "    plt.show()\n",
    "    \n",
    "occupancy2(\"Emulab\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911461f4",
   "metadata": {},
   "source": [
    "### Scrape the Emulab Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3faf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://ops.emulab.net/rfbaseline/Emulab/'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    links = soup.find_all('a', href=True)\n",
    "    \n",
    "    file_urls = [link['href'] for link in links if link['href'].endswith('.gz')]\n",
    "    \n",
    "    for file_url in file_urls:\n",
    "        if (file_url.startswith(\"./cbrssdr1-ustar\") and int(file_url.split(\"-\")[-1].split(\".\")[0])>1611516022) :\n",
    "            download_response = requests.get(url+file_url[2:])\n",
    "            if download_response.status_code == 200:\n",
    "                filename = file_url.split('/')[-1]\n",
    "                filename = filename.split(\":\")[0]+\"_\"+filename.split(\":\")[1]\n",
    "                filepath = f'./emulab_data/{filename}'\n",
    "                with open(filepath, 'wb') as file:\n",
    "                    file.write(download_response.content)\n",
    "            else:\n",
    "                print(f'Failed to download {file_url}')\n",
    "        else:\n",
    "            continue\n",
    "else:\n",
    "    print('Failed to retrieve the webpage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7af28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
